ğŸ“Œ Mobile Banking Review Analysis â€“ Week 2 Challenge

This repository contains all work completed for 10 Academy â€“ AI Mastery Program, Week 2 Challenge, focusing on mobile banking reviews, including data scraping, cleaning, sentiment analysis, thematic extraction, and reporting.

The project is structured into two major tasks:

Task-1: Data Collection â€” Web Scraping & Cleaning

Task-2: Sentiment & Theme Analysis â€” VADER-based sentiment + Keyword thematic modeling

A detailed Interim Report (4 pages) is also included, summarizing the scraping pipeline and early insights from the data.

ğŸ“ Folder Structure
mobile-banking-reviews-Challenge-week2/
â”‚
â”œâ”€â”€ Scripts/                         # All Python scripts for Task-1 & Task-2
â”‚   â”œâ”€â”€ task1_scraper.py             # Web scraping logic
â”‚   â”œâ”€â”€ task1_cleaner.py             # Cleaning & preprocessing
â”‚   â”œâ”€â”€ Sentiment_demo.py  # VADER sentiment + thematic modeling
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ task1_scraping_cleaning.ipynb   # Task-1 exploratory notebook
â”‚   â”œâ”€â”€ task2_analysis.ipynb            # Task-2 analysis & visualizations
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ raw/
â”‚       â”‚   â””â”€â”€ reviews_raw.csv         # Original scraped reviews
â”‚       â”œâ”€â”€ interim/
â”‚       â””â”€â”€ processed/
â”‚           â””â”€â”€ reviews_clean.csv       # Cleaned dataset
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ Interim_Report.pdf              # 4-page early analysis report
â”‚
â”œâ”€â”€ README.md                           # Project documentation
â””â”€â”€ requirements.txt                    # All dependencies

ğŸš€ Task 1 â€” Data Scraping & Early Cleaning
Objective

Collect mobile banking reviews from the provided Google Play Store URLs.

Key Steps

Automated scraping using BeautifulSoup / Play Store API wrapper

Extracted:

Reviewer name

Rating

Review text

Date

Cleaned text by removing:

Emojis

HTML artifacts

URLs

Stopwords

Normalized whitespaces

Stored outputs in:

notebooks/data/raw/reviews_raw.csv
notebooks/data/processed/reviews_clean.csv

Deliverables

âœ” task1_scraper.py
âœ” task1_cleaner.py
âœ” task1_scraping_cleaning.ipynb

ğŸ” Task 2 â€” Sentiment + Thematic Analysis
Sentiment Analysis

Because NLTK and spaCy had installation issues, I implemented a stable, modern approach using:

VADER Sentiment Analyzer (works perfectly on short review text)

Output columns:

sentiment_compound

sentiment_label â†’ positive / neutral / negative

Thematic Extraction

Due to gensim failing to install, themes were extracted using:

Keyword frequency analysis

Simple noun extraction (regex-based, no spaCy dependency)

Manual clustering of themes into:

Customer Support

Usability & UI

Bugs / Technical issues

Performance

Security & Trust

Deliverables

âœ” task2_sentiment_thematic.py
âœ” task2_analysis.ipynb

ğŸŒ± Current Branches in the Repository
Branch	Purpose
main	Production-ready code, final results, reports
task-1	Contains scraping + cleaning scripts & notebook
task-2	Sentiment + thematic analysis scripts & notebook

All development happened in the task-specific branches, then merged into main after completion.

ğŸ“„ Interim Report (4 Pages)

The Interim Report summarizes:

1. Task Overview

Purpose of the challenge

Data sources

Requirements

2. Scraping Strategy

Tools used: BeautifulSoup / Requests

How pagination or dynamic loading was handled

Data schema collected

Error handling & retry logic

3. Data Cleaning Pipeline

Duplicate removal

Tokenization

Lowercasing

Stopword filtering

Text normalization

4. Early Insights

Distribution of ratings

Early sentiment distribution

Initial keyword frequency

Example positive & negative reviews

5. Challenges & Mitigations

Play Store DOM issues

NLTK installation failures

Gensim / spaCy incompatibility with Python 3.14

Solutions used (VADER, regex noun extraction)

6. Structure of the Repository

Explaining the folder structure listed above.

ğŸ›  How to Run the Project
1ï¸âƒ£ Create environment
python -m venv .venv
source .venv/bin/activate      # Mac/Linux
.\.venv\Scripts\activate       # Windows

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Run Task-1 scripts
python Scripts/task1_scraper.py
python Scripts/task1_cleaner.py

4ï¸âƒ£ Run Task-2 analysis
python Scripts/task2_sentiment_thematic.py


Or use the Jupyter Notebooks inside /notebooks.

ğŸ™Œ Author

Kalkidan Asdesach
10 Academy â€“ Cohort 8
AI Mastery Program | Week 2 Challenge
