# ğŸ“Œ Mobile Banking Review Analysis â€“ Week 2 Challenge

This repository contains all work completed for **10 Academy â€“ AI Mastery Program, Week 2 Challenge**, focusing on **mobile banking reviews**. The project covers data scraping, cleaning, sentiment analysis, thematic extraction, and reporting.

---

## ğŸ“ Project Structure

```
mobile-banking-reviews-Challenge-week2/
â”‚
â”œâ”€â”€ Scripts/                         # Python scripts for Task-1 & Task-2
â”‚   â”œâ”€â”€ task1_scraper.py             # Web scraping logic
â”‚   â”œâ”€â”€ task1_cleaner.py             # Cleaning & preprocessing
â”‚   â””â”€â”€ Sentiment_demo.py            # VADER sentiment + thematic extraction
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ task1_scraping_cleaning.ipynb   # Task-1 exploratory notebook
â”‚   â”œâ”€â”€ task2_analysis.ipynb            # Task-2 analysis & visualizations
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ raw/
â”‚       â”‚   â””â”€â”€ reviews_raw.csv         # Original scraped reviews
â”‚       â”œâ”€â”€ interim/
â”‚       â””â”€â”€ processed/
â”‚           â””â”€â”€ reviews_clean.csv       # Cleaned dataset
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ Interim_Report.pdf              # 4-page early analysis report
â”‚
â”œâ”€â”€ README.md                           # Project documentation
â””â”€â”€ requirements.txt                    # Python dependencies
```

---

## ğŸš€ Task 1 â€” Data Scraping & Cleaning

**Objective:** Collect mobile banking reviews from Google Play Store and preprocess them for analysis.

**Key Steps:**

* Automated scraping using **BeautifulSoup** / Play Store API wrapper
* Extracted:

  * Reviewer name
  * Rating
  * Review text
  * Review date
* Cleaned text by removing:

  * Emojis
  * HTML artifacts
  * URLs
  * Stopwords
  * Extra whitespace

**Outputs:**

* `notebooks/data/raw/reviews_raw.csv` â€“ Raw scraped reviews
* `notebooks/data/processed/reviews_clean.csv` â€“ Cleaned dataset

**Deliverables:**

âœ” `task1_scraper.py`
âœ” `task1_cleaner.py`
âœ” `task1_scraping_cleaning.ipynb`

---

## ğŸ” Task 2 â€” Sentiment & Thematic Analysis

**Sentiment Analysis:**

* Implemented using **VADER Sentiment Analyzer**
* Output columns:

  * `sentiment_score` â†’ compound sentiment score
  * `sentiment_label` â†’ positive / neutral / negative

**Thematic Extraction:**

* Due to installation issues with **gensim** and **spaCy**, themes were extracted via:

  * Keyword frequency analysis
  * Regex-based noun extraction (no spaCy dependency)
* Manual clustering of themes into:

  * Customer Support
  * Usability & UI
  * Bugs / Technical issues
  * Performance
  * Security & Trust

**Deliverables:**

âœ” `task2_sentiment_thematic.py`
âœ” `task2_analysis.ipynb`

---

## ğŸŒ± Branches

| Branch | Purpose                                          |
| ------ | ------------------------------------------------ |
| main   | Production-ready code, final results, reports    |
| task-1 | Scraping + cleaning scripts & notebook           |
| task-2 | Sentiment + thematic analysis scripts & notebook |
| task-3 | PostgreSQL database insertion scripts/notebooks  |
| task-4 | Insights, visualizations, and recommendations    |

All development happened in **task-specific branches**, then merged into `main` after completion.

---

## ğŸ“„ Interim Report (4 Pages)

The report summarizes:

1. **Task Overview:** Purpose, data sources, requirements
2. **Scraping Strategy:** Tools used, pagination handling, data schema
3. **Data Cleaning Pipeline:** Duplicate removal, tokenization, normalization
4. **Early Insights:** Rating distribution, sentiment distribution, keyword frequency
5. **Challenges & Solutions:** Play Store DOM issues, NLTK/gensim/spaCy installation issues
6. **Repository Structure:** Folder and file organization

---

## ğŸ›  How to Run the Project

1ï¸âƒ£ **Create virtual environment**

```bash
python -m venv .venv
# Activate
# Mac/Linux
source .venv/bin/activate
# Windows
.\.venv\Scripts\activate
```

2ï¸âƒ£ **Install dependencies**

```bash
pip install -r requirements.txt
```

3ï¸âƒ£ **Run Task-1 scripts**

```bash
python Scripts/task1_scraper.py
python Scripts/task1_cleaner.py
```

4ï¸âƒ£ **Run Task-2 analysis**

```bash
python Scripts/task2_sentiment_thematic.py
```

Or use the Jupyter Notebooks in `/notebooks`.

---

## ğŸ™Œ Author

**Kalkidan Asdesach**
10 Academy â€“ AI Mastery Program

---

